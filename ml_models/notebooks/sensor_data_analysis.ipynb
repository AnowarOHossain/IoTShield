{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470d9750",
   "metadata": {},
   "source": [
    "# IoTShield - Sensor Data Analysis & ML Model Training\n",
    "\n",
    "## Privacy-Preserving Real-Time Home Automation System\n",
    "\n",
    "This notebook provides comprehensive analysis and machine learning model training for the IoTShield sensor anomaly detection system.\n",
    "\n",
    "**Dataset**: `sensor_data.csv` (10,000 samples)\n",
    "**Goal**: Train models to detect anomalies in IoT sensor data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04c002",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Dataset\n",
    "\n",
    "First, we'll import required libraries and load the sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b998b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Configure display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29901d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../dataset/sensor_data.csv')\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Display basic information\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(f\"Time Range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nStatistical Summary:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a47a2d",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Cleaning\n",
    "\n",
    "Check for data quality issues and clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nMissing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"No missing values found!\")\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate Rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Removed {duplicates} duplicate rows\")\n",
    "\n",
    "# Anomaly distribution\n",
    "print(f\"\\nAnomaly Distribution:\")\n",
    "anomaly_counts = df['is_anomaly'].value_counts()\n",
    "print(f\"Normal samples: {anomaly_counts[0]} ({anomaly_counts[0]/len(df)*100:.2f}%)\")\n",
    "print(f\"Anomaly samples: {anomaly_counts[1]} ({anomaly_counts[1]/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Device distribution\n",
    "print(f\"\\nDevice Distribution:\")\n",
    "print(df['device_id'].value_counts())\n",
    "\n",
    "# Location distribution\n",
    "print(f\"\\nLocation Distribution:\")\n",
    "print(df['location'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a0e89",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 3.1 Sensor Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensor distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Sensor Data Distributions (Normal vs Anomaly)', fontsize=16, fontweight='bold')\n",
    "\n",
    "sensors = ['temperature', 'humidity', 'gas_level', 'flame_detected', 'motion_detected', 'light_level']\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "\n",
    "for idx, sensor in enumerate(sensors):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    # Separate normal and anomaly data\n",
    "    normal_data = df[df['is_anomaly'] == 0][sensor]\n",
    "    anomaly_data = df[df['is_anomaly'] == 1][sensor]\n",
    "    \n",
    "    # Plot histograms\n",
    "    ax.hist([normal_data, anomaly_data], bins=30, label=['Normal', 'Anomaly'], \n",
    "            color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'{sensor.replace(\"_\", \" \").title()}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sensor distribution plots generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb8efe",
   "metadata": {},
   "source": [
    "### 3.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aea7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "numeric_cols = ['temperature', 'humidity', 'gas_level', 'flame_detected', 'motion_detected', 'light_level', 'is_anomaly']\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap - Sensor Features', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStrong correlations with anomaly:\")\n",
    "anomaly_corr = correlation_matrix['is_anomaly'].sort_values(ascending=False)\n",
    "for feature, corr in anomaly_corr.items():\n",
    "    if feature != 'is_anomaly':\n",
    "        print(f\"  • {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d96729",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Prepare features for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for ML model\n",
    "feature_columns = ['temperature', 'humidity', 'gas_level', 'flame_detected', 'motion_detected', 'light_level']\n",
    "target_column = 'is_anomaly'\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[feature_columns].values\n",
    "y = df[target_column].values\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFeatures (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nFeature columns: {feature_columns}\")\n",
    "print(f\"Target column: {target_column}\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"\\nFeatures standardized (mean=0, std=1)\")\n",
    "print(f\"Scaled features shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ff1f3",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split\n",
    "\n",
    "Split data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ef295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"   • X_train: {X_train.shape}\")\n",
    "print(f\"   • y_train: {y_train.shape}\")\n",
    "print(f\"   • Anomalies: {y_train.sum()} ({y_train.sum()/len(y_train)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTesting set:\")\n",
    "print(f\"   • X_test: {X_test.shape}\")\n",
    "print(f\"   • y_test: {y_test.shape}\")\n",
    "print(f\"   • Anomalies: {y_test.sum()} ({y_test.sum()/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nData split completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06354b1b",
   "metadata": {},
   "source": [
    "## 6. Train Machine Learning Models\n",
    "\n",
    "### 6.1 Isolation Forest (Unsupervised Anomaly Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c396bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest model\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING ISOLATION FOREST MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.1,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining model...\")\n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_iso = iso_forest.predict(X_test)\n",
    "# Convert predictions: 1 for normal, -1 for anomaly -> Convert to 0 and 1\n",
    "y_pred_iso = (y_pred_iso == -1).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_iso = accuracy_score(y_test, y_pred_iso)\n",
    "\n",
    "print(f\"\\nModel trained successfully!\")\n",
    "print(f\"Test Accuracy: {accuracy_iso*100:.2f}%\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_iso, target_names=['Normal', 'Anomaly']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67966f33",
   "metadata": {},
   "source": [
    "### 6.2 Random Forest Classifier (Supervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining model...\")\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nModel trained successfully!\")\n",
    "print(f\"Test Accuracy: {accuracy_rf*100:.2f}%\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Feature importance\n",
    "print(f\"\\nFeature Importance:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': rf_classifier.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d46159",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b76867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Model': ['Isolation Forest', 'Random Forest Classifier'],\n",
    "    'Accuracy': [accuracy_iso * 100, accuracy_rf * 100],\n",
    "    'Type': ['Unsupervised', 'Supervised']\n",
    "})\n",
    "\n",
    "print(\"\\n\", models_comparison.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Confusion Matrix - Isolation Forest\n",
    "cm_iso = confusion_matrix(y_test, y_pred_iso)\n",
    "sns.heatmap(cm_iso, annot=True, fmt='d', cmap='Blues', ax=axes[0], \n",
    "            xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "axes[0].set_title(f'Isolation Forest\\nAccuracy: {accuracy_iso*100:.2f}%', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Confusion Matrix - Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "axes[1].set_title(f'Random Forest Classifier\\nAccuracy: {accuracy_rf*100:.2f}%', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Determine best model\n",
    "best_model_name = 'Random Forest Classifier' if accuracy_rf > accuracy_iso else 'Isolation Forest'\n",
    "best_accuracy = max(accuracy_rf, accuracy_iso)\n",
    "print(f\"\\nBest Model: {best_model_name} (Accuracy: {best_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc144f5",
   "metadata": {},
   "source": [
    "## 8. Save the Best Model\n",
    "\n",
    "Save the trained model and scaler for deployment in IoTShield system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best performing model\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save Isolation Forest (used by IoTShield system)\n",
    "iso_forest_path = '../isolation_forest_model.pkl'\n",
    "joblib.dump(iso_forest, iso_forest_path)\n",
    "print(f\"\\nIsolation Forest saved: {iso_forest_path}\")\n",
    "\n",
    "# Save Random Forest Classifier\n",
    "rf_classifier_path = '../random_forest_classifier.pkl'\n",
    "joblib.dump(rf_classifier, rf_classifier_path)\n",
    "print(f\"Random Forest saved: {rf_classifier_path}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = '../scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Scaler saved: {scaler_path}\")\n",
    "\n",
    "print(f\"\\nAll models and preprocessors saved successfully!\")\n",
    "print(f\"\\nModel files location: ml_models/\")\n",
    "print(f\"   • isolation_forest_model.pkl (Anomaly Detection)\")\n",
    "print(f\"   • random_forest_classifier.pkl (Classification)\")\n",
    "print(f\"   • scaler.pkl (Feature Scaling)\")\n",
    "\n",
    "print(f\"\\nModels are ready for deployment in IoTShield system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39e8d0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Completed Tasks:\n",
    "1. **Dataset Loaded**: 10,000 sensor readings with 6 features\n",
    "2. **Data Preprocessing**: No missing values, no duplicates\n",
    "3. **EDA**: Visualized sensor distributions and correlations\n",
    "4. **Feature Engineering**: Standardized features for ML\n",
    "5. **Model Training**: \n",
    "   - Isolation Forest (Unsupervised)\n",
    "   - Random Forest Classifier (Supervised)\n",
    "6. **Model Evaluation**: Compared accuracy and confusion matrices\n",
    "7. **Model Deployment**: Saved models for IoTShield system\n",
    "\n",
    "### Key Findings:\n",
    "- **Anomaly Rate**: ~10% of samples\n",
    "- **Strongest Correlations**: Gas level and flame detection with anomalies\n",
    "- **Best Model**: Check comparison results above\n",
    "- **Models Ready**: For real-time anomaly detection in IoTShield\n",
    "\n",
    "### Next Steps:\n",
    "1. Integrate models with Django backend\n",
    "2. Test real-time predictions with IoT simulator\n",
    "3. Monitor model performance with live data\n",
    "4. Retrain with real sensor data when available"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
